#!/usr/bin/env python

from sys import argv, stdout, stderr
from collections import Counter
from copy import deepcopy
from getopt import gnu_getopt, GetoptError
from multiprocessing import Pool
import pysam as ps
import numpy as np
import re
import argparse

PADDING = 0

# An assumption here is that most pairs overlap, and hence I would not 
# have Ns in the consensus in families.
class Options():
    pass

class Alignment:
    def __init__(self, aln):
        self.pos = aln.pos
        self.query_sequence = aln.query_sequence
        self.cigartuples = aln.cigartuples

class Consensus:
    """Consensus that result from alignments of the same read family."""
    min_coverage_per_umi = None
    min_agreement = None

    def __init__(self, start, end):
        self.profile = {}

    # add a new alignment to the profile
    def add_alignment(self, aln):
        qseq = aln.query_sequence
        qual = aln.query_qualities
        qndx = 0
        rndx = aln.pos
        for op, oplen in aln.cigartuples:
            if op == 0 or op == 7 or op == 8:
                # match / mismatch
                for i in range(0, oplen):
                    if rndx not in self.profile: self.profile[rndx] = Counter()
                    if qual[qndx] > 0:
                        self.profile[rndx][qseq[qndx]] += 1
                    qndx += 1
                    rndx += 1
            elif op == 1:
                # insertion
                assert rndx-1 in self.profile
                toadd = True
                for i in range(qndx-1, qndx+oplen):
                    if qual[i] == 0:
                        toadd = False
                        break
                if toadd:
                    self.profile[rndx-1][qseq[qndx-1]] -= 1
                    self.profile[rndx-1][qseq[qndx-1:qndx+oplen]] += 1
                qndx += oplen
            elif op == 2:
                # deletion
                for i in range(0, oplen):
                    if rndx not in self.profile: self.profile[rndx] = Counter()
                    self.profile[rndx]['*'] += 1
                    rndx += 1
            elif op == 3 or op == 9:
                assert False
            elif op == 4:
                qndx += oplen
            elif op == 5:
                pass
            elif op == 6:
                assert False
            else:
                assert False

    def __str__(self):
        positions = self.profile.keys()
        s = min(positions)
        e = max(positions)

        sequence = []
        for p in range(s,e+1):
            if p in self.profile:
                profile = self.profile[p]
                if not profile:
                    sequence.append(".")
                    continue

                alleles = [(y,x) for x,y in profile.items()]
                alleles.sort(reverse = True)
                covering = sum([x for x,y in alleles])
                agreeing = alleles[0][0]

                if covering < Consensus.min_coverage_per_umi:
                    sequence.append(".")
                else:
                    if (agreeing*1./covering) >= Consensus.min_agreement:
                        b = alleles[0][1]
                        if b != '*':
                            sequence.append(b[0])
                    else:
                        sequence.append('N')
            else:
                sequence.append(".")

        return "".join(sequence)

def process_interval(intervals):
    return _process_interval(*intervals)

def _process_interval(chrom, start, end, options):
    region = "%s:%d-%d" % (chrom, start, end)

    # get all reads overlapping the region. Only include the reads that are
    # within the region of interest on both sides. Using those reads, start
    # building a consensus profile per umi
    umi_families = Counter()
    bamfile = ps.AlignmentFile(options.bamfile, 'r')
    for aln in bamfile.fetch(region=region):
        assert aln.is_unmapped == False
        assert aln.is_secondary == False
        assert aln.is_supplementary == False
        assert aln.is_qcfail == False
        if aln.pos < start or aln.aend > end: continue
        umi = re.split('\:|\+', aln.query_name)[options.umi_indx]
        umi_families[umi] += 1
    bamfile.close()

    family_counter = deepcopy(umi_families)
    consensus = {}
    sequences = []
    bamfile = ps.AlignmentFile(options.bamfile, 'r')
    for aln in bamfile.fetch(region=region):
        if aln.pos < start or aln.aend > end: continue
        umi = re.split('\:|\+', aln.query_name)[options.umi_indx]
        if umi_families[umi] >= options.min_reads_per_umi:
            if umi not in consensus:
                consensus[umi] = Consensus(start, end)
            consensus[umi].add_alignment(aln)
            family_counter[umi] -= 1
            if family_counter[umi] == 0:
                seq = str(consensus[umi])
                counts = Counter(seq)

                nfrac = 0.0
                if 'N' in counts:
                    nfrac = counts['N']*1./sum([y for x,y in counts.items() if x != '.'])
                if nfrac < options.max_ns_in_consensus:
                    seq = seq.replace('.','N')
                    sequences.append((umi, seq))
                for k,v in consensus[umi].profile.items():
                    del[v]
                del(consensus[umi])

    del consensus        
    del umi_families 
    del family_counter
    return sequences

def run(min_reads_per_umi, min_coverage_per_umi, min_agreement,
        max_ns_in_consensus, max_template_length, num_threads, argo):
    global PADDING

    # lets get all the user specified options into a structure
    options = Options()
    options.min_reads_per_umi = min_reads_per_umi
    options.min_coverage_per_umi = min_coverage_per_umi
    options.min_agreement = min_agreement
    options.max_ns_in_consensus = max_ns_in_consensus
    options.max_template_length = max_template_length
    options.bamfile = argo[0]

    Consensus.min_coverage_per_umi = min_coverage_per_umi
    Consensus.min_agreement = min_agreement

    # lets make sure we can identify the UMIs
    options.umi_indx = None
    for aln in ps.AlignmentFile(argo[0]):
        tokens = re.split('\:|\+', aln.query_name)
        for indx, token in enumerate(tokens):
            if sum([x.isalpha() for x in token]) == len(token) == 16:
                options.umi_indx = indx     
        break
    assert options.umi_indx is not None

    # read in all the intervals
    intervals = []
    with open(argo[1], 'r') as f:
        for line in f:
            chrom, start, end, _ = line.strip().split()
            start = int(start) - PADDING
            end = int(end) + PADDING
            intervals.append((chrom, start, end, options))
    intervals.sort()
    
    tmpfile = open(argo[2], "w")
    if num_threads == 1:
        for sequences in map(process_interval, intervals):
            for umi, seq in sequences:
                print >> tmpfile, ">%s" % umi
                print >> tmpfile, seq
    else: 
        pool = Pool(num_threads)
        for sequences in pool.imap_unordered(process_interval, intervals):
            for umi, seq in sequences:
                print >> tmpfile, ">%s" % umi
                print >> tmpfile, seq
    tmpfile.close()
    
    seen = set()
    ignore = set()
    
    with open(argo[2], 'r') as f:
        for line in f:
            if line.startswith(">"):
                umi = line.strip()[1:]
                if umi in seen:
                    ignore.add(umi)
                else:
                    seen.add(umi)
    
    o = stdout
    with open(argo[2], 'r') as f:
        while True:
            header = f.readline()
            if not header: break
            seq = f.readline()
            umi = header.strip()[1:]
            if umi not in ignore:
                print >> o, header,
                print >> o, seq,


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('-r', action='store', type=int, default=5,
                        required=True, 
                        help='minimum number of reads per umi required')
    parser.add_argument('-c', action='store', type=int, default=5,
                        required=True, 
                        help='minimum coverage at a loci of a umi')
    parser.add_argument('-a', action='store', type=float, default=0.9,
                        required=True, 
                        help='minimum agreement to call consensus')
    parser.add_argument('-n', action='store', type=float, default=0.1,
                        required=True, 
                        help='max allowed fraction of Ns in consensus')
    parser.add_argument('-t', action='store', type=int, default=300,
                        required=True, 
                        help='max expected template length')
    parser.add_argument('-p', action='store', type=int, default=1,
                        required=True,
                        help='number of processes to use')
    args, others = parser.parse_known_args(args=argv[1:])
    assert len(others) == 3

    run(args.r, args.c, args.a, args.n, args.t, args.p, others)
